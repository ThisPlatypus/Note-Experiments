{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Import library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "\n",
    "import flwr as fl\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import Subset\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CIFAR100\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# create training dataset\n",
    "trainset = CIFAR100(root='./data', train=True, download=True, transform=transform)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "NUM_CLIENTS = 50\n",
    "\n",
    "def load_datasets(num_clients: int):\n",
    "    # Download and transform CIFAR-100 (train and test)\n",
    "    transform = transforms.Compose(\n",
    "      [transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
    "    )\n",
    "    trainset = CIFAR100(\"./dataset\", train=True, download=True, transform=transform)\n",
    "    testset = CIFAR100(\"./dataset\", train=False, download=True, transform=transform)\n",
    "\n",
    "    #Create the subsets\n",
    "    trainloaders = []\n",
    "    valloaders = []\n",
    "    for x in range(0,num_clients):\n",
    "        # We create a tensor that has `True` at an index if the sample belongs to class\n",
    "        idx0 = torch.tensor(trainset.targets) == x\n",
    "        idx1 = torch.tensor(trainset.targets) == x+50\n",
    "        idx = idx0 | idx1\n",
    "        idx0t = torch.tensor(testset.targets) == x\n",
    "        idx1t = torch.tensor(testset.targets) == x+50\n",
    "        idxt = idx0t | idx1t\n",
    "        #We then need to convert this into a list of indices at which we have True.\n",
    "        train_indices = idx.nonzero().reshape(-1)\n",
    "        val_indices = idxt.nonzero().reshape(-1)\n",
    "        #append new subset\n",
    "        ds_train=torch.utils.data.Subset(trainset,  train_indices)\n",
    "        ds_val= torch.utils.data.Subset(testset,  val_indices)\n",
    "        trainloaders.append(DataLoader(ds_train, batch_size=32, shuffle=True))\n",
    "        valloaders.append(DataLoader(ds_val, batch_size=32, shuffle=True))\n",
    "    return trainloaders, valloaders\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainloaders, valloaders = load_datasets(NUM_CLIENTS)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.utils.data.dataloader.DataLoader"
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(trainloaders[0])"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
